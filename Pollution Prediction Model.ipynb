{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "e287c297-b3e7-4240-8d73-1d18c324ce53",
      "cell_type": "code",
      "source": "# Import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error, accuracy_score\nimport statsmodels.api as sm\nimport warnings\n\nwarnings.filterwarnings('ignore')\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "ed929f81-9426-4607-b974-3c9a4c4bdea6",
      "cell_type": "code",
      "source": "# 1. Data Loading & Inspection\n# ---------------------------\n\n# Load CSV\ndf = pd.read_csv('CHNADIGARH DATA.csv')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "id": "d1b934a0-0d5d-4418-b8f0-449b79427499",
      "cell_type": "code",
      "source": "# Inspect\nprint(\"\\n--- Dataset Head ---\")\nprint(df.head())\n\nprint(\"\\n--- Dataset Info ---\")\nprint(df.info())\n\nprint(\"\\n--- Summary Statistics ---\")\nprint(df.describe())\n\nprint(\"\\n--- Missing Values Before Cleaning ---\")\nprint(df.isnull().sum())",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n--- Dataset Head ---\n            To Date   PM2.5    PM10     NO    NO2    NOx    NH3   SO2    CO  \\\n0  03-01-2024 00:00   95.77  142.61   3.25  41.37  23.67  22.18  8.27  1.18   \n1  04-01-2024 00:00  123.76  189.76  20.27  34.17  31.85  22.90  2.84  1.44   \n2  05-01-2024 00:00   77.04  115.82  13.17  28.34  25.14  26.32  0.92  1.20   \n3  06-01-2024 00:00  115.04  167.34  10.34  31.36  24.80  34.99  3.16  1.36   \n4  07-01-2024 00:00  133.54  183.38  13.61  31.42  27.28  35.38  1.16  1.42   \n\n   Ozone  ...  Toluene  Eth-Benzene  MP-Xylene  O-Xylene     RH    WS      WD  \\\n0  22.59  ...    12.35         3.09       2.55       NaN  87.25  0.51  226.29   \n1  32.64  ...    20.69         5.88       5.43       NaN  86.27  0.37  205.25   \n2  17.19  ...    16.58         5.28       4.37       NaN  78.58  0.48  288.74   \n3  15.98  ...    13.41         4.32       3.78       NaN  70.66  0.40  256.57   \n4  18.34  ...    16.28         5.84       4.67       NaN  74.05  0.44  257.42   \n\n      SR  Xylene     AT  \n0  29.25    2.34   9.95  \n1  30.46    5.20  10.01  \n2  33.41    3.64   8.34  \n3  29.77    3.32   8.36  \n4  31.73    4.15   8.87  \n\n[5 rows x 21 columns]\n\n--- Dataset Info ---\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 560 entries, 0 to 559\nData columns (total 21 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   To Date      560 non-null    object \n 1   PM2.5        560 non-null    float64\n 2   PM10         560 non-null    float64\n 3   NO           555 non-null    float64\n 4   NO2          556 non-null    float64\n 5   NOx          556 non-null    float64\n 6   NH3          556 non-null    float64\n 7   SO2          560 non-null    float64\n 8   CO           560 non-null    float64\n 9   Ozone        560 non-null    float64\n 10  Benzene      533 non-null    float64\n 11  Toluene      533 non-null    float64\n 12  Eth-Benzene  533 non-null    float64\n 13  MP-Xylene    533 non-null    float64\n 14  O-Xylene     0 non-null      float64\n 15  RH           549 non-null    float64\n 16  WS           559 non-null    float64\n 17  WD           559 non-null    float64\n 18  SR           552 non-null    float64\n 19  Xylene       533 non-null    float64\n 20  AT           560 non-null    float64\ndtypes: float64(20), object(1)\nmemory usage: 89.8+ KB\nNone\n\n--- Summary Statistics ---\n            PM2.5        PM10          NO         NO2         NOx         NH3  \\\ncount  560.000000  560.000000  555.000000  556.000000  556.000000  556.000000   \nmean    62.023589  118.584375   12.002631   34.401331   27.965450   49.141169   \nstd     47.080942   65.653531   11.472449   14.016198   14.697832   27.397845   \nmin      3.560000   16.070000    2.030000    7.520000    8.320000   14.330000   \n25%     31.125000   71.555000    4.520000   23.755000   17.197500   30.170000   \n50%     47.810000  103.070000    7.970000   30.470000   23.840000   38.800000   \n75%     78.452500  150.600000   14.690000   44.395000   33.705000   60.130000   \nmax    334.410000  471.790000   71.820000  107.810000   88.000000  170.060000   \n\n              SO2          CO       Ozone     Benzene     Toluene  \\\ncount  560.000000  560.000000  560.000000  533.000000  533.000000   \nmean    11.857946    0.994607   59.721125    1.933865   10.013677   \nstd      5.308088    0.269323   29.165019    1.221491    5.725842   \nmin      0.210000    0.000000    7.020000    0.130000    1.780000   \n25%      7.327500    0.810000   33.782500    1.100000    5.410000   \n50%     11.555000    0.940000   58.510000    1.610000    8.880000   \n75%     15.430000    1.132500   81.092500    2.540000   13.350000   \nmax     30.040000    2.450000  143.930000    8.410000   29.500000   \n\n       Eth-Benzene   MP-Xylene  O-Xylene          RH          WS          WD  \\\ncount   533.000000  533.000000       0.0  549.000000  559.000000  559.000000   \nmean      2.995685    3.525403       NaN   60.993752    0.498873  216.938157   \nstd       2.304963    2.566965       NaN   19.594419    0.231169   48.654063   \nmin       0.400000    0.370000       NaN   13.220000    0.140000  125.410000   \n25%       1.600000    1.660000       NaN   49.050000    0.360000  177.130000   \n50%       2.590000    3.260000       NaN   66.150000    0.470000  211.800000   \n75%       3.870000    4.670000       NaN   75.740000    0.590000  254.060000   \nmax      20.370000   17.920000       NaN   93.670000    2.510000  329.120000   \n\n               SR      Xylene          AT  \ncount  552.000000  533.000000  560.000000  \nmean    74.194076    2.742326   25.722036  \nstd     68.575121    2.096199    8.286413  \nmin      8.000000    0.230000    0.920000  \n25%     40.150000    1.200000   19.982500  \n50%     54.460000    2.540000   27.385000  \n75%     81.480000    3.640000   31.785000  \nmax    563.940000   15.230000   49.670000  \n\n--- Missing Values Before Cleaning ---\nTo Date          0\nPM2.5            0\nPM10             0\nNO               5\nNO2              4\nNOx              4\nNH3              4\nSO2              0\nCO               0\nOzone            0\nBenzene         27\nToluene         27\nEth-Benzene     27\nMP-Xylene       27\nO-Xylene       560\nRH              11\nWS               1\nWD               1\nSR               8\nXylene          27\nAT               0\ndtype: int64\n"
        }
      ],
      "execution_count": 5
    },
    {
      "id": "b078263b-2bd9-4fbc-954b-e9fa51f80660",
      "cell_type": "code",
      "source": "\n# 2. Data Cleaning\n# ---------------------------\n\n# Drop rows where PM2.5 (target) is missing\ndf = df.dropna(subset=['PM2.5'])\n# Fill any remaining missing feature values with median (more robust)\nfeatures = features.fillna(features.median())\n\n\n# Fill remaining numeric missing values with median\ndf.fillna(df.median(numeric_only=True), inplace=True)\n\n# Features for models (exclude targets)\nfeatures = df.select_dtypes(include=[np.number]).drop(\n    ['PM2.5', 'PM2.5_Category'], axis=1, errors='ignore'\n)\n\n# Fill missing feature values with median (instead of dropping)\nfeatures = features.fillna(features.median())\n\n# Align targets with cleaned features\nX_reg = features\ny_reg = df.loc[features.index, 'PM2.5']\ny_clf = df.loc[features.index, 'PM2.5_Category']\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "id": "bbc937b7-a2ae-4d52-bff6-0f70de12302a",
      "cell_type": "code",
      "source": "# 3. Setup Columns (Change as needed)\n# ---------------------------\n\nregression_target = 'PM2.5'                  # Continuous target for regression\nclassification_target = 'PM2.5_Category'     # Derived category from PM2.5 levels\ntime_series_variable = 'PM2.5'               # Forecast PM2.5 over time\n\n# Features for ML models\nfeatures = df.select_dtypes(include=[np.number]).drop(\n    [regression_target, classification_target], axis=1, errors='ignore'\n)\n\n# ---------------------------\n# 3. Feature Engineering\n# ---------------------------\n\n# Classification Target: PM2.5 Category\ndef classify_pm25(value):\n    if value <= 60:\n        return 0  # Good\n    elif value <= 120:\n        return 1  # Moderate\n    else:\n        return 2  # Poor\n\ndf['PM2.5_Category'] = df['PM2.5'].apply(classify_pm25)\n\n# Features for models (exclude targets)\nfeatures = df.select_dtypes(include=[np.number]).drop(\n    ['PM2.5', 'PM2.5_Category'], axis=1, errors='ignore'\n)\n\n# Drop any rows with NaNs in features (final cleanup)\nfeatures = features.dropna()\n\n# Align targets with cleaned features\nX_reg = features\ny_reg = df.loc[features.index, 'PM2.5']\ny_clf = df.loc[features.index, 'PM2.5_Category']\n\n# ---------------------------",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "id": "c6c44a63-da3a-4c65-8fe8-b06e065f71f7",
      "cell_type": "code",
      "source": "# 4. Regression Models\n# ---------------------------\n\nprint(\"\\n--- Running Regression Models ---\")\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n\n# Scale\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Linear Regression\nlr_model = LinearRegression()\nlr_model.fit(X_train_scaled, y_train)\ny_pred_lr = lr_model.predict(X_test_scaled)\nmse_lr = mean_squared_error(y_test, y_pred_lr)\n\n# Polynomial Regression (degree=2)\npoly = PolynomialFeatures(degree=2)\nX_train_poly = poly.fit_transform(X_train_scaled)\nX_test_poly = poly.transform(X_test_scaled)\n\npoly_model = LinearRegression()\npoly_model.fit(X_train_poly, y_train)\ny_pred_poly = poly_model.predict(X_test_poly)\nmse_poly = mean_squared_error(y_test, y_pred_poly)\n\nprint(f\"Linear Regression MSE: {mse_lr:.4f}\")\nprint(f\"Polynomial Regression (degree 2) MSE: {mse_poly:.4f}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n--- Running Regression Models ---\n"
        },
        {
          "ename": "<class 'ValueError'>",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Running Regression Models ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Scale\u001b[39;00m\n\u001b[1;32m     10\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2851\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2481\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2478\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2485\u001b[0m     )\n\u001b[1;32m   2487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 23
    },
    {
      "id": "61a007c4-af9e-4486-adac-a814993b040c",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}